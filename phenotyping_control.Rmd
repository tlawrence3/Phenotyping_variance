---
title: "Phenotyping Variance"
author: "Travis J. Lawrence"
date: "1/29/2019"
output:
  html_document:
    fig_caption: yes
    number_sections: yes
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(readr)
library(reshape2)
library(ggplot2)
library(captioner)
library(knitr)
fig_nums <- captioner(prefix = "Fig.")
fig.1_cap <- fig_nums(name = "fig_1", 
                      caption = "Percent deviation of measured area (cm^2) by well and image analysis protocol")
fig.2_cap <- fig_nums(name = "fig_2", 
                        caption = "Plot of plant surface area measures by plate well and image analysis algorithm. Lower and upper of each box correspond to the first and third quartiles. Error bars indicate either the full range of the data or 1.5 * IQR, whichever is smaller. Dots represent the measured plant surface area.")
table_nums <- captioner(prefix = "Table")
tab.1_cap <- table_nums(name = "Table_1", 
                        caption = "Linear model of percent deviation with wells and protocol as factors")
```

# Overview
Below are the results from the reproducible of phenotype measurements study that Sara performed. She repeated phenotypic measurements of the same plate 12 times. Time between measurements was equal to the time to dark adapt plants. The photos were analyzed for the variance in the measurement of plant surface area across time points using three different algorithms referred to as edge.test, edgeerode.test, localfilter.test, and test. Each algorithm was implemented in Fiji and briefly described below:

* edge.test:
    + Convert picture to 8-bit
    + Use the `find edges` algorithm
    + Convert picture to binary
    + Use the `fill holes` algorithm
    + Take measurements
* edgeerode.test:
    + Run the first four steps of `edge.test`
    + Use the `erode` function
    + Use the `dilate` function
    + Take measurements
* localfilter.test:
    + Convert picture to 8-bit
    + Run `Auto Local Threshold` using the `method=Phansalkar radius=15 parameter_1=0 parameter_2=0 white` options
    + Convert picture to binary
    + Take measurements
* test:
    + Adjust contrast using `setMinAndMax(2, 130);`. These values were determined by manually optimizing contrast for three photos.
    + Convert picture to binary
    + Take measurements

# Analyses
Percent deviation was calculated for each well and algorithm using the code below and plotted in Fig. 1. The overall distribution of the data for each well and algorithm is plotted in Fig. 2.

```{r, echo=FALSE, warning = FALSE, message = FALSE}
data <- read_csv("error.variance.csv")
data.persd <- as.data.frame(dcast(data, Protocol~Well,
                                  fun.aggregate = function(x){return(sprintf('%0.2f', sd(x)/mean(x)*100))}))
data.persd <- melt(data.persd, id = c("Protocol"), variable.name = "Well")                            
data.persd$value <- as.double(data.persd$value)
```

```{r, echo=FALSE, fig.width = 15, fig.align='center',fig.cap = fig.1_cap}
ggplot(data.persd, aes(fill=Protocol, y=value, x=Well)) + 
  geom_bar(position="dodge", stat="identity") + ylab("Percent Deviation")+
  theme(axis.text=element_text(size=12),
        axis.title=element_text(size=16,face="bold"),
        legend.text=element_text(size=16))
```
```{r, echo=FALSE, fig.width = 15, fig.align='center',fig.cap = fig.2_cap}
data$Well<-as.factor(data$Well)
ggplot(data, aes(color=Protocol, y=`Area(cm2)`, x=Well)) +
  geom_boxplot(position=position_dodge(0.8)) +
  geom_jitter(position=position_dodge(0.8)) +
  theme(axis.text=element_text(size=12),
        axis.title=element_text(size=16,face="bold"),
        legend.text=element_text(size=16))


```


```{r Table_1, echo=FALSE, fig.cap = tab.1_cap}
kable(summary(lm(data.persd$value~data.persd$Well + data.persd$Protocol))$coef, digits=2)
```


Time to play around with a simulation dataset. What is the minimum slope value necessary to be 95% confident that growth indeed occured. In other words, what is the slope value that we need to be above the noise. 




```{r, echo=FALSE}

#getting to know the data
#data %>% select(Protocol) %>% unique() # from that we find localfilter.test
#find the mean and sd for localfilter.test regardless of well position or rep.

library(tidyverse)
data %>% filter(Protocol == "localfilter.test") %>% summarise(mean_area = mean(`Area(cm2)`), SD_area = sd(`Area(cm2)`))


```

Ok - try the same thing but within well

```{r, echo=FALSE}

data %>% filter(Protocol == "localfilter.test") %>% group_by(Well)  %>% summarise(mean_area = mean(`Area(cm2)`), SD_area = sd(`Area(cm2)`))


```

Is there a relationship between SD and size?

```{r, echo=FALSE}
trash<-data %>% filter(Protocol == "localfilter.test") %>% group_by(Well)  %>% summarise(mean_area = mean(`Area(cm2)`), SD_area = sd(`Area(cm2)`))

plot(trash$mean_area, trash$SD_area)
abline(h=0.07, col = "lightblue")

```

Not sure what to make of that. above 0.35 mean area is associated with large SD. whats up? so not going to use the average sd and mean from above. looking at this, anything below 0.35 cm2 area would have  a max sd of 0.06 or so. will go with that, and a mean of 0.25 area. 

```{r, echo=FALSE}

n<-length

sim.data <- data.frame(
  genotype = seq(1,100000),
  week1 = rnorm(100000, 0.35, 0.06),
  week2 = rnorm(100000, 0.35, 0.06),
  week3 = rnorm(100000, 0.35, 0.06),
  week4 = rnorm(100000, 0.35, 0.06) 
)

sim.data$genotype<-as.character(sim.data$genotype)
#check with str(sim.data)

```


siumulated data is made. now run the model across 1000,000 rows of data. 

```{r, echo=FALSE}
library(broom)

#to tidy the data in long form
tidy.sim.data <- gather(sim.data, weeksampled, area_cm2, -genotype)

#changing the categorical 'initial', 'week1' etc to numeric days for lm
tidy.sim.data.2<- tidy.sim.data %>% mutate(sampletime = replace(weeksampled, weeksampled == "week1", 0)) %>%  mutate(sampletime = replace(sampletime, weeksampled == "week2", 7)) %>% mutate(sampletime = replace(sampletime, weeksampled  == "week3", 14)) %>% mutate(sampletime = replace(sampletime, weeksampled == "week4", 21))

tidy.sim.data.2$sampletime<-as.numeric(tidy.sim.data.2$sampletime)


#running the lm model across all rows genotypes

lm.results<- tidy.sim.data.2 %>% group_by(genotype) %>% do(fitdata = lm(area_cm2 ~ sampletime, data = .))

#getting tidy data output from model run
lmSlopePvalue <- tidy(lm.results, fitdata) %>% select(genotype, term, estimate, p.value) %>% filter(term =="sampletime")

lmRsquare <- glance(lm.results, fitdata) %>% select(genotype, r.squared)

#tidy data output
lmtidyoutput<-left_join(lmSlopePvalue, lmRsquare, by = c("genotype" = "genotype")) %>% arrange(p.value)

# lm model parameter distributions

par(mfrow=c(1,3))
hist(lmtidyoutput$estimate, main = "lm slope")
hist(lmtidyoutput$p.value, main = "P value")
hist(lmtidyoutput$r.squared, main = "r2")
```


Need to translate this into a 95% CI

THe graph from the lm slope looks normally distributed. so will calculate the 95% CI for that distribution

```{r, echo=FALSE}

#need to find mean, sd, and n

paste(mean(lmtidyoutput$estimate), "is the slope mean for samples <= 0.35 cm2")
paste(sd(lmtidyoutput$estimate), "is the slope sd for samples <= 0.35 cm2")


n <- 100000
m <- -2.656641e-05
s <- 0.003832171

error <- qnorm(0.975)*s/sqrt(n)
left_interval <- m - error
right_interval <- m + error

paste(left_interval, "is the left interval for 95% CI")
paste(right_interval, "is the right interval for 95% CI")


```

the above gives you 95% CI for for samples that 0.35 cm2 or below. Meaning that slopes outside these intervals may be real -- or above the noise in our dataset.





